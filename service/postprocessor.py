from __future__ import annotations

import logging
import zipfile
from html.parser import HTMLParser
from pathlib import Path

logger = logging.getLogger(__name__)


# ── HTML Validation ────────────────────────────────────────────────────────────

class _StructureChecker(HTMLParser):
    def __init__(self):
        super().__init__()
        self.has_html = False
        self.has_head = False
        self.has_body = False

    def handle_starttag(self, tag, attrs):
        if tag == "html":
            self.has_html = True
        elif tag == "head":
            self.has_head = True
        elif tag == "body":
            self.has_body = True


def validate_html(html: str) -> tuple[bool, list[str]]:
    errors: list[str] = []
    checker = _StructureChecker()

    try:
        checker.feed(html)
    except Exception as e:
        errors.append(f"Parser error: {e}")
        return False, errors

    if not checker.has_html:
        errors.append("Missing <html> tag")
    if not checker.has_body:
        errors.append("Missing <body> tag")
    if not html.rstrip().endswith(">"):
        errors.append("HTML appears truncated (does not end with '>')")

    return len(errors) == 0, errors


def check_required_sections(html: str) -> list[str]:
    missing = []
    if "api/get-news" not in html:
        missing.append("news section (api/get-news)")
    if "api/plan-search" not in html:
        missing.append("plan search section (api/plan-search)")
    if "api/plan-strategy" not in html:
        missing.append("plan strategy section (api/plan-strategy)")
    return missing


# ── ZIP packaging ──────────────────────────────────────────────────────────────

def pack_zip(html: str, domain: str, job_id: str, output_dir: Path) -> Path:
    output_dir.mkdir(parents=True, exist_ok=True)
    zip_path = output_dir / f"{job_id}.zip"

    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("index.html", html.encode("utf-8"))
        zf.writestr(
            "README.txt",
            f"Website: {domain}\nJob ID: {job_id}\nGenerated by WebGen\n".encode("utf-8"),
        )

    return zip_path


# ── Main entry point ──────────────────────────────────────────────────────────

def postprocess(html: str, domain: str, job_id: str, output_dir: Path) -> tuple[Path, list[str]]:
    """
    Validate, check required sections, and pack to ZIP.
    Returns (zip_path, warnings).
    Raises on hard failures.
    """
    warnings: list[str] = []

    is_valid, errors = validate_html(html)
    if not is_valid:
        logger.warning(f"[{job_id}] HTML validation issues: {errors}")
        warnings.extend(errors)

    missing = check_required_sections(html)
    if missing:
        logger.warning(f"[{job_id}] Missing required sections: {missing}")
        warnings.extend([f"Missing required section: {s}" for s in missing])

    zip_path = pack_zip(html, domain, job_id, output_dir)
    logger.info(f"[{job_id}] Packed → {zip_path} ({zip_path.stat().st_size // 1024} KB)")

    return zip_path, warnings
